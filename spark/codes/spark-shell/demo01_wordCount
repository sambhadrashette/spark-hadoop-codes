file = sc.textFile("/home/spark/hadoop-2.7.3/LICENSE.txt")

lines = file.map(lambda line: line.lower())

words = lines.flatMap(lambda line: line.split())

word1s = words.map(lambda word: (word,1))

wordcounts = word1s.reduceByKey(lambda acc,cnt: acc + cnt)

result = wordcounts.collect()

print(result)